{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1776895,"sourceType":"datasetVersion","datasetId":1056391},{"sourceId":7455460,"sourceType":"datasetVersion","datasetId":4339697},{"sourceId":6055,"sourceType":"modelInstanceVersion","modelInstanceId":4676}],"dockerImageVersionId":30042,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment Analysis using BERT\n\nBERT (Bidirectionnal Encoder Representations for Transformers) is a “new method of pre-training language representations” developed by Google and released in late 2018.","metadata":{"id":"QbM7x-5UEzUR"}},{"cell_type":"markdown","source":"### Import Libraries and Set the intial variables","metadata":{"id":"Q6hKNfAlEzUS"}},{"cell_type":"code","source":"pip install --upgrade pip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"vezpsX-7GphM","outputId":"a7164402-8a7b-4e4c-e118-ce6498ba4f2e","execution":{"iopub.status.busy":"2024-02-07T03:53:25.029921Z","iopub.execute_input":"2024-02-07T03:53:25.030313Z","iopub.status.idle":"2024-02-07T03:53:32.878758Z","shell.execute_reply.started":"2024-02-07T03:53:25.030276Z","shell.execute_reply":"2024-02-07T03:53:32.877388Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (3.0.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.17.5)\nRequirement already satisfied: tokenizers==0.8.0-rc4 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.8.0rc4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.10)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.23.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.45.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2020.4.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.91)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.43)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (1.14.0)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.25.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.12.5)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.1)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom collections import defaultdict\nfrom textwrap import wrap\n\n# Torch ML libraries\nimport transformers\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Misc.\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"WtQykqrfEzUT","execution":{"iopub.status.busy":"2024-02-07T03:53:33.904274Z","iopub.execute_input":"2024-02-07T03:53:33.904647Z","iopub.status.idle":"2024-02-07T03:53:39.769274Z","shell.execute_reply.started":"2024-02-07T03:53:33.904615Z","shell.execute_reply":"2024-02-07T03:53:39.768422Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set intial variables and constants\n%config InlineBackend.figure_format='retina'\n\n# Graph Designs\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\nrcParams['figure.figsize'] = 12, 8\n\n# Random seed for reproducibilty\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\n\n# Set GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"gRINjFWWEzUb","execution":{"iopub.status.busy":"2024-02-07T03:54:55.061681Z","iopub.execute_input":"2024-02-07T03:54:55.062092Z","iopub.status.idle":"2024-02-07T03:54:55.136900Z","shell.execute_reply.started":"2024-02-07T03:54:55.062036Z","shell.execute_reply":"2024-02-07T03:54:55.135917Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Load the data","metadata":{"id":"LQOFO5MSEzUf"}},{"cell_type":"code","source":"df = pd.read_csv('../input/covid-19/Corona_NLP_train.csv', encoding = 'latin-1')\ndf.shape","metadata":{"id":"g6b5ajqzEzUg","outputId":"a7888891-5d69-42b7-a1e0-ccdbe75f04e4","execution":{"iopub.status.busy":"2024-02-07T03:54:56.528817Z","iopub.execute_input":"2024-02-07T03:54:56.529191Z","iopub.status.idle":"2024-02-07T03:54:56.689390Z","shell.execute_reply.started":"2024-02-07T03:54:56.529150Z","shell.execute_reply":"2024-02-07T03:54:56.688263Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(41157, 6)"},"metadata":{}}]},{"cell_type":"code","source":"# Let's have a look at the data \ndf.head()","metadata":{"id":"eQ5Uwg8xEzUk","outputId":"2b23324b-d208-462f-d011-95c2f7847390","execution":{"iopub.status.busy":"2024-02-07T03:54:57.010611Z","iopub.execute_input":"2024-02-07T03:54:57.010972Z","iopub.status.idle":"2024-02-07T03:54:57.029433Z","shell.execute_reply.started":"2024-02-07T03:54:57.010941Z","shell.execute_reply":"2024-02-07T03:54:57.028366Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   UserName  ScreenName   Location     TweetAt  \\\n0      3799       48751     London  16-03-2020   \n1      3800       48752         UK  16-03-2020   \n2      3801       48753  Vagabonds  16-03-2020   \n3      3802       48754        NaN  16-03-2020   \n4      3803       48755        NaN  16-03-2020   \n\n                                       OriginalTweet           Sentiment  \n0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n1  advice Talk to your neighbours family to excha...            Positive  \n2  Coronavirus Australia: Woolworths to give elde...            Positive  \n3  My food stock is not the only one which is emp...            Positive  \n4  Me, ready to go at supermarket during the #COV...  Extremely Negative  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>Extremely Negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We can see that the most relevant column for us is content and replyContent and the score as well.","metadata":{"id":"7zqGIlGIEzUo"}},{"cell_type":"code","source":"# Let's check for missing values \ndf.isnull().sum()","metadata":{"id":"24xNLIJlEzUo","outputId":"eae6af5f-068a-480e-acdd-3c78b3e8a81b","execution":{"iopub.status.busy":"2024-02-07T03:54:57.788990Z","iopub.execute_input":"2024-02-07T03:54:57.789378Z","iopub.status.idle":"2024-02-07T03:54:57.816576Z","shell.execute_reply.started":"2024-02-07T03:54:57.789342Z","shell.execute_reply":"2024-02-07T03:54:57.815807Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"UserName            0\nScreenName          0\nLocation         8590\nTweetAt             0\nOriginalTweet       0\nSentiment           0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"There are missing values in some of the columns but Content and score don't have a missing value. We can also look at the class balance. \n\nWe will be alloting three classes:- \n1. Positive (Score: 4-5)\n2. Neutral (Score: 3)\n3. Negative (Score: 1-2)","metadata":{"id":"YJjld_WSEzUt"}},{"cell_type":"code","source":"# Let's have a look at the class balance.\nsns.countplot(df.Sentiment)\nplt.xlabel('review score');","metadata":{"id":"lWJJv8q7EzUu","outputId":"0a5797e5-60e6-4f35-d37a-50014f8bdb98","execution":{"iopub.status.busy":"2024-02-07T03:54:58.777579Z","iopub.execute_input":"2024-02-07T03:54:58.777949Z","iopub.status.idle":"2024-02-07T03:54:59.069103Z","shell.execute_reply.started":"2024-02-07T03:54:58.777912Z","shell.execute_reply":"2024-02-07T03:54:59.068286Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 864x576 with 1 Axes>","image/png":"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\n"},"metadata":{"image/png":{"width":753,"height":489}}}]},{"cell_type":"markdown","source":"We can see that we have more positive classes than negative and low number of neutral class. I have kept neutral less to focus more on positive and negative classes. Let's allot classes based on scores now. \n\n* 0 - negative\n* 1 - neutral \n* 2 - positive","metadata":{"id":"trIBdPvXEzUy"}},{"cell_type":"code","source":"# Function to convert score to sentiment\ndef to_sentiment(rating):\n    \n    if(rating=='Neutral'):\n        return 2\n    elif rating=='Positive':\n        return 3\n    elif rating=='Extremely Positive':\n        return 4\n    elif rating=='Negative':\n        return 1\n    elif rating=='Extremely Negative':\n        return 0\n\n# Apply to the dataset \ndf['sentiment'] = df.Sentiment.apply(to_sentiment)","metadata":{"id":"MyK4bEuhEzUy","execution":{"iopub.status.busy":"2024-02-07T03:55:00.913461Z","iopub.execute_input":"2024-02-07T03:55:00.913856Z","iopub.status.idle":"2024-02-07T03:55:00.952553Z","shell.execute_reply.started":"2024-02-07T03:55:00.913815Z","shell.execute_reply":"2024-02-07T03:55:00.951793Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Plot the distribution\nclass_names = ['Extremely negative', 'Negative','Neutral', 'Positive','Extremely Positive']\nax = sns.countplot(df.sentiment)\nplt.xlabel('review sentiment')\nax.set_xticklabels(class_names)","metadata":{"id":"VzaRGLGDEzU2","outputId":"df731374-977a-4f04-ba82-ab60c0c5ffa8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing\n\nMachine Learning models don’t work with raw text. You need to convert text to numerical representation. BERT requires even more attention when it comes to this representation. \n\nHere are the requirements:\n\n* Add special tokens to separate sentences and do classification\n* Pass sequences of constant length (introduce padding)\n* Create array of 0s (pad token) and 1s (real token) called attention mask\n\nBERT offers a few model architectures and I will be using one of them combined with manual preprocessing. I am using the cased version which considers GREAT and great to be to different entities and BAD might be given more focus than bad.  \n\nThe tokenizer will break the sentence into words and give numerical values to each word. ","metadata":{"id":"JeJSe1hIEzU5"}},{"cell_type":"code","source":"# Set the model name\nMODEL_NAME = 'bert-base-cased'\n\n# Build a BERT based tokenizer\n# tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\ntokenizer = BertTokenizer.from_pretrained('bert-base-cased')","metadata":{"id":"Uj5eXyqYEzU6","outputId":"4a6b71ec-7503-4884-c669-08383d60225e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Some of the common BERT tokens\nprint(tokenizer.sep_token, tokenizer.sep_token_id) # marker for ending of a sentence\nprint(tokenizer.cls_token, tokenizer.cls_token_id) # start of each sentence, so BERT knows we’re doing classification\nprint(tokenizer.pad_token, tokenizer.pad_token_id) # special token for padding\nprint(tokenizer.unk_token, tokenizer.unk_token_id) # tokens not found in training set ","metadata":{"id":"5XqmI4AZEzU9","outputId":"773ac222-7aa8-48d6-eeab-2239646a805a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"BERT works with fixed-length sequences. We’ll use a simple strategy to choose the max length. Let’s store the token length of each review.","metadata":{"id":"r-ridSzLEzVA"}},{"cell_type":"code","source":"# Store length of each review \ntoken_lens = []\n\n# Iterate through the content slide\nfor txt in df.OriginalTweet:\n    tokens = tokenizer.encode(txt, max_length=512)\n    token_lens.append(len(tokens))","metadata":{"id":"oBIUYNVoEzVB","outputId":"fbdb58c8-ea3b-44b7-a77f-950c5c18564a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the distribution of review lengths \nsns.distplot(token_lens)\nplt.xlim([0, 256]);\nplt.xlabel('Token count')","metadata":{"id":"bpVn-ndyEzVE","outputId":"70db118d-4736-4b61-db2d-bc9de8e0d977","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the reviews seem to contain less than 120 tokens, but we’ll be on the safe side and choose a maximum length of 160. ","metadata":{"id":"QMj924FHEzVI"}},{"cell_type":"code","source":"MAX_LEN = 160","metadata":{"id":"blPAZJOPEzVJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preparing Torch Dataset\n\nTo enter data into a PyTorch, we need a more robust data generator class. We will return the review text as well to validate our predictions easily. ","metadata":{"id":"5owK7q5hEzVL"}},{"cell_type":"code","source":"class GPReviewDataset(Dataset):\n    # Constructor Function \n    def __init__(self, reviews, targets, tokenizer, max_len):\n        self.reviews = reviews\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    \n    # Length magic method\n    def __len__(self):\n        return len(self.reviews)\n    \n    # get item magic method\n    def __getitem__(self, item):\n        review = str(self.reviews[item])\n        target = self.targets[item]\n        \n        # Encoded format to be returned \n        encoding = self.tokenizer.encode_plus(\n            review,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            pad_to_max_length=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n        \n        return {\n            'review_text': review,\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'targets': torch.tensor(target, dtype=torch.long)\n        }","metadata":{"id":"Sbakw3KIEzVM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a 80% train data and 10% test and 10% validation data","metadata":{"id":"Q4_AxWjuEzVP"}},{"cell_type":"code","source":"df_train, df_test = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)\ndf_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)\n\nprint(df_train.shape, df_val.shape, df_test.shape)","metadata":{"id":"qIXH-Y-gEzVQ","outputId":"162ea24f-7bc4-4631-bdc7-8a795334934d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a dataloader to release data in batches.","metadata":{"id":"SQeS3OqGEzVS"}},{"cell_type":"code","source":"def create_data_loader(df, tokenizer, max_len, batch_size):\n    ds = GPReviewDataset(\n        reviews=df.OriginalTweet.to_numpy(),\n        targets=df.sentiment.to_numpy(),\n        tokenizer=tokenizer,\n        max_len=max_len\n    )\n    \n    return DataLoader(\n        ds,\n        batch_size=batch_size,\n        num_workers=0\n    )","metadata":{"id":"c7SCbUlmEzVT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create train, test and val data loaders\nBATCH_SIZE = 16\ntrain_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\nval_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\ntest_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)","metadata":{"id":"31-GApKIEzVW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Examples \ndata = next(iter(train_data_loader))\nprint(data.keys())\n\nprint(data['input_ids'].shape)\nprint(data['attention_mask'].shape)\nprint(data['targets'].shape)","metadata":{"id":"6ZPtu0jjEzVc","outputId":"dd0bb267-6d3d-4ce1-8c81-76b8e4d1beca","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sentiment Classification with BERT and Hugging Face\n\nWe’ll use the basic BertModel and build our sentiment classifier on top of it. Let’s load the model","metadata":{"id":"bnRQaNQ0EzVf"}},{"cell_type":"code","source":"# Load the basic BERT model \nbert_model = BertModel.from_pretrained(MODEL_NAME)","metadata":{"id":"1oVuK0UUEzVg","outputId":"354aaaea-b336-41cc-a1de-8a5583545f17","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build the Sentiment Classifier class \nclass SentimentClassifier(nn.Module):\n    \n    # Constructor class \n    def __init__(self, n_classes):\n        super(SentimentClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(MODEL_NAME)\n        self.drop = nn.Dropout(p=0.3)\n        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n    \n    # Forward propagaion class\n    def forward(self, input_ids, attention_mask):\n        _, pooled_output = self.bert(\n          input_ids=input_ids,\n          attention_mask=attention_mask\n        )\n        #  Add a dropout layer \n        output = self.drop(pooled_output)\n        return self.out(output)\n    \n#     def __init__(self, bert):\n#         super(BERT_Arch, self).__init__()\n#         self.bert = BertModel.from_pretrained('bert-base-uncased')\n#         self.conv = nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(3, 768), padding=True)\n#         self.relu = nn.ReLU()\n#         self.pool = nn.MaxPool2d(kernel_size=3, stride=1)\n#         self.dropout = nn.Dropout(0.1)\n#         self.fc = nn.Linear(442, 3) # before : 442 with max_length 36 # 806 with max_length 64\n#         self.flat = nn.Flatten()\n#         self.softmax = nn.LogSoftmax(dim=1)\n\n#     def forward(self, sent_id, mask):\n#         _, _, all_layers = self.bert(sent_id, attention_mask=mask, output_hidden_states=True)\n#         # all_layers  = [13, 32, 64, 768]\n#         x = torch.transpose(torch.cat(tuple([t.unsqueeze(0) for t in all_layers]), 0), 0, 1)\n#         del all_layers\n#         gc.collect()\n#         torch.cuda.empty_cache()\n#         x = self.pool(self.dropout(self.relu(self.conv(self.dropout(x)))))\n#         x = self.fc(self.dropout(self.flat(self.dropout(x))))\n#         return self.softmax(x)","metadata":{"id":"v98I1vshEzVi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n @Time : 15/12/2020 19:01\n @Author : Alaa Grable\n \"\"\"\n\n!pip install transformers==3.0.0\n!pip install emoji\nimport gc\n#import os\nimport emoji as emoji\nimport re\nimport string\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom transformers import AutoModel\nfrom transformers import BertModel, BertTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-02-07T03:54:00.731559Z","iopub.execute_input":"2024-02-07T03:54:00.731975Z","iopub.status.idle":"2024-02-07T03:54:16.246196Z","shell.execute_reply.started":"2024-02-07T03:54:00.731926Z","shell.execute_reply":"2024-02-07T03:54:16.244917Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers==3.0.0 in /opt/conda/lib/python3.7/site-packages (3.0.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.0) (1.17.5)\nRequirement already satisfied: tokenizers==0.8.0-rc4 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.0) (0.8.0rc4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.0) (20.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.0) (3.0.10)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.0) (2.23.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.0) (4.45.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.0) (2020.4.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.0) (0.1.91)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.0) (0.0.43)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==3.0.0) (2.4.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==3.0.0) (1.14.0)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.0) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.0) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.0) (1.25.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.0) (2020.12.5)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.0) (7.1.1)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.0) (0.14.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: emoji in /opt/conda/lib/python3.7/site-packages (0.6.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"\n\nclass BERT_Arch(nn.Module):\n\n    def __init__(self, bert):\n        super(BERT_Arch, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.conv = nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(3, 768), padding=True)\n        self.relu = nn.ReLU()\n        self.pool = nn.MaxPool2d(kernel_size=3, stride=1)\n        self.dropout = nn.Dropout(0.1)\n        self.fc = nn.Linear(442, 5) # before : 442 with max_length 36 # 806 with max_length 64\n        self.flat = nn.Flatten()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, sent_id, mask):\n        _, _, all_layers = self.bert(sent_id, attention_mask=mask, output_hidden_states=True)\n        # all_layers  = [13, 32, 64, 768]\n        x = torch.transpose(torch.cat(tuple([t.unsqueeze(0) for t in all_layers]), 0), 0, 1)\n        del all_layers\n#         gc.collect()\n#         torch.cuda.empty_cache()\n        x = self.pool(self.dropout(self.relu(self.conv(self.dropout(x)))))\n        x = self.fc(self.dropout(self.flat(self.dropout(x))))\n        return self.softmax(x)\n\n\ndef read_dataset():\n    data = pd.read_csv(\"/kaggle/input/covid-19/Corona_NLP_train.csv\", encoding = 'latin-1')\n    data = data.drop(['ScreenName', 'Location', 'TweetAt'], axis=1)\n    #data = data.loc[0:9599,:]\n    print(len(data))\n    # Apply to the dataset \n    data['sentiment'] = data.Sentiment.apply(to_sentiment)\n    return data['OriginalTweet'].tolist(), data['sentiment']\n\n\ndef pre_process_dataset(values):\n    new_values = list()\n    # Emoticons\n    emoticons = [':-)', ':)', '(:', '(-:', ':))', '((:', ':-D', ':D', 'X-D', 'XD', 'xD', 'xD', '<3', '</3', ':\\*',\n                 ';-)',\n                 ';)', ';-D', ';D', '(;', '(-;', ':-(', ':(', '(:', '(-:', ':,(', ':\\'(', ':\"(', ':((', ':D', '=D',\n                 '=)',\n                 '(=', '=(', ')=', '=-O', 'O-=', ':o', 'o:', 'O:', 'O:', ':-o', 'o-:', ':P', ':p', ':S', ':s', ':@',\n                 ':>',\n                 ':<', '^_^', '^.^', '>.>', 'T_T', 'T-T', '-.-', '*.*', '~.~', ':*', ':-*', 'xP', 'XP', 'XP', 'Xp',\n                 ':-|',\n                 ':->', ':-<', '$_$', '8-)', ':-P', ':-p', '=P', '=p', ':*)', '*-*', 'B-)', 'O.o', 'X-(', ')-X']\n\n    for value in values:\n        # Remove dots\n        text = value.replace(\".\", \"\").lower()\n        text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n        users = re.findall(\"[@]\\w+\", text)\n        for user in users:\n            text = text.replace(user, \"<user>\")\n        urls = re.findall(r'(https?://[^\\s]+)', text)\n        if len(urls) != 0:\n            for url in urls:\n                text = text.replace(url, \"<url >\")\n        for emo in text:\n            if emo in emoji.UNICODE_EMOJI:\n                text = text.replace(emo, \"<emoticon >\")\n        for emo in emoticons:\n            text = text.replace(emo, \"<emoticon >\")\n        numbers = re.findall('[0-9]+', text)\n        for number in numbers:\n            text = text.replace(number, \"<number >\")\n        text = text.replace('#', \"<hashtag >\")\n        text = re.sub(r\"([?.!,¿])\", r\" \", text)\n        text = \"\".join(l for l in text if l not in string.punctuation)\n        text = re.sub(r'[\" \"]+', \" \", text)\n        new_values.append(text)\n    return new_values\n\n\ndef data_process(data, labels):\n    input_ids = []\n    attention_masks = []\n    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n    for sentence in data:\n        bert_inp = bert_tokenizer.__call__(sentence, max_length=36,\n                                           padding='max_length', pad_to_max_length=True,\n                                           truncation=True, return_token_type_ids=False)\n\n        input_ids.append(bert_inp['input_ids'])\n        attention_masks.append(bert_inp['attention_mask'])\n    #del bert_tokenizer\n    #gc.collect()\n    #torch.cuda.empty_cache()\n    input_ids = np.asarray(input_ids)\n    attention_masks = np.array(attention_masks)\n    labels = np.array(labels)\n    return input_ids, attention_masks, labels\n\n\ndef load_and_process():\n    data, labels = read_dataset()\n    num_of_labels = len(labels.unique())\n    input_ids, attention_masks, labels = data_process(pre_process_dataset(data), labels)\n\n    return input_ids, attention_masks, labels\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-07T03:54:16.248454Z","iopub.execute_input":"2024-02-07T03:54:16.248778Z","iopub.status.idle":"2024-02-07T03:54:16.284735Z","shell.execute_reply.started":"2024-02-07T03:54:16.248741Z","shell.execute_reply":"2024-02-07T03:54:16.283855Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device='cpu'","metadata":{"execution":{"iopub.status.busy":"2024-02-07T03:54:22.367260Z","iopub.execute_input":"2024-02-07T03:54:22.367642Z","iopub.status.idle":"2024-02-07T03:54:22.371737Z","shell.execute_reply.started":"2024-02-07T03:54:22.367604Z","shell.execute_reply":"2024-02-07T03:54:22.370579Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# function to train the model\ndef train():\n    model.train()\n\n    total_loss, total_accuracy = 0, 0\n\n    # empty list to save model predictions\n    total_preds = []\n\n    # iterate over batches\n    total = len(train_dataloader)\n    for i, batch in enumerate(train_dataloader):\n\n        step = i+1\n        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n        filledLength = int(100 * step // total)\n        bar = '█' * filledLength + '>'  *(filledLength < 100) + '.' * (99 - filledLength)\n        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n\n        # push the batch to gpu\n        batch = [r.to(device) for r in batch]\n        sent_id, mask, labels = batch\n        del batch\n#         gc.collect()\n#         torch.cuda.empty_cache()\n        # clear previously calculated gradients\n        model.zero_grad()\n\n        # get model predictions for the current batch\n        #sent_id = torch.tensor(sent_id).to(device).long()\n        preds = model(sent_id, mask)\n\n        # compute the loss between actual and predicted values\n        loss = cross_entropy(preds, labels)\n\n        # add on to the total loss\n        total_loss += float(loss.item())\n\n        # backward pass to calculate the gradients\n        loss.backward()\n\n        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        # update parameters\n        optimizer.step()\n\n        # model predictions are stored on GPU. So, push it to CPU\n        #preds = preds.detach().cpu().numpy()\n\n        # append the model predictions\n        #total_preds.append(preds)\n        total_preds.append(preds.detach().cpu().numpy())\n\n#     gc.collect()\n#     torch.cuda.empty_cache()\n\n    # compute the training loss of the epoch\n    avg_loss = total_loss / (len(train_dataloader)*batch_size)\n\n    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n    # reshape the predictions in form of (number of samples, no. of classes)\n    total_preds = np.concatenate(total_preds, axis=0)\n\n    # returns the loss and predictions\n    return avg_loss, total_preds\n\n\n# function for evaluating the model\ndef evaluate():\n    print(\"\\n\\nEvaluating...\")\n\n    # deactivate dropout layers\n    model.eval()\n\n    total_loss, total_accuracy = 0, 0\n\n    # empty list to save the model predictions\n    total_preds = []\n\n    # iterate over batches\n    total = len(val_dataloader)\n    for i, batch in enumerate(val_dataloader):\n        \n        step = i+1\n        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n        filledLength = int(100 * step // total)\n        bar = '█' * filledLength + '>' * (filledLength < 100) + '.' * (99 - filledLength)\n        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n\n        # push the batch to gpu\n        batch = [t.to(device) for t in batch]\n\n        sent_id, mask, labels = batch\n        del batch\n#         gc.collect()\n#         torch.cuda.empty_cache()\n        # deactivate autograd\n        with torch.no_grad():\n\n            # model predictions\n            preds = model(sent_id, mask)\n\n            # compute the validation loss between actual and predicted values\n            loss = cross_entropy(preds, labels)\n\n            total_loss += float(loss.item())\n            #preds = preds.detach().cpu().numpy()\n\n            #total_preds.append(preds)\n            total_preds.append(preds.detach().cpu().numpy())\n\n#     gc.collect()\n#     torch.cuda.empty_cache()\n\n    # compute the validation loss of the epoch\n    avg_loss = total_loss / (len(val_dataloader)*batch_size)\n\n    # reshape the predictions in form of (number of samples, no. of classes)\n    total_preds = np.concatenate(total_preds, axis=0)\n\n    return avg_loss, total_preds\n\n# Specify the GPU\n# Setting up the device for GPU usage\ndevice = 'cpu'\nprint(device)\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Load Data-set ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\ninput_ids, attention_masks, labels = load_and_process()\ndf = pd.DataFrame(list(zip(input_ids, attention_masks)), columns=['input_ids', 'attention_masks'])\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ class distribution ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n\n# class = class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither\n# ~~~~~~~~~~ Split train data-set into train, validation and test sets  ~~~~~~~~~~#\ntrain_text, temp_text, train_labels, temp_labels = train_test_split(df, labels,\n                             random_state=2018, test_size=0.2, stratify=labels)\n\nval_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n                         random_state=2018, test_size=0.5, stratify=temp_labels)\n\ndel temp_text\n# gc.collect()\n# torch.cuda.empty_cache()\n\ntrain_count = len(train_labels)\ntest_count = len(test_labels)\nval_count = len(val_labels)\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n\n# ~~~~~~~~~~~~~~~~~~~~~ Import BERT Model and BERT Tokenizer ~~~~~~~~~~~~~~~~~~~~~#\n# import BERT-base pretrained model\nbert = AutoModel.from_pretrained('bert-base-uncased')\n# bert = AutoModel.from_pretrained('bert-base-uncased')\n# Load the BERT tokenizer\n#tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Tokenization ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n# for train set\ntrain_seq = torch.tensor(train_text['input_ids'].tolist())\ntrain_mask = torch.tensor(train_text['attention_masks'].tolist())\ntrain_y = torch.tensor(train_labels.tolist())\n\n# for validation set\nval_seq = torch.tensor(val_text['input_ids'].tolist())\nval_mask = torch.tensor(val_text['attention_masks'].tolist())\nval_y = torch.tensor(val_labels.tolist())\n\n# for test set\ntest_seq = torch.tensor(test_text['input_ids'].tolist())\ntest_mask = torch.tensor(test_text['attention_masks'].tolist())\ntest_y = torch.tensor(test_labels.tolist())\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Create DataLoaders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n# define a batch size\nbatch_size = 32\n\n# wrap tensors\ntrain_data = TensorDataset(train_seq, train_mask, train_y)\n\n# sampler for sampling the data during training\ntrain_sampler = RandomSampler(train_data)\n\n# dataLoader for train set\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\n# wrap tensors\nval_data = TensorDataset(val_seq, val_mask, val_y)\n\n# sampler for sampling the data during training\nval_sampler = SequentialSampler(val_data)\n\n# dataLoader for validation set\nval_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Freeze BERT Parameters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n# freeze all the parameters\nfor param in bert.parameters():\n    param.requires_grad = False\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n\n# pass the pre-trained BERT to our define architecture\nmodel = BERT_Arch(bert)\n# push the model to GPU\nmodel = model.to(device)\n\n# optimizer from hugging face transformers\nfrom transformers import AdamW\n\n# define the optimizer\noptimizer = AdamW(model.parameters(), lr=2e-5)\n\n#from sklearn.utils.class_weight import compute_class_weight\n\n# compute the class weights\n#class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n\n#print(class_wts)\n\n# convert class weights to tensor\n#weights = torch.tensor(class_wts, dtype=torch.float)\n#weights = weights.to(device)\n\n# loss function\n#cross_entropy = nn.NLLLoss(weight=weights)\ncross_entropy = nn.NLLLoss()\n\n# set initial loss to infinite\nbest_valid_loss = float('inf')\n\n# empty lists to store training and validation loss of each epoch\n#train_losses = []\n#valid_losses = []\n\n#if os.path.isfile(\"/content/drive/MyDrive/saved_weights.pth\") == False:\n#if os.path.isfile(\"saved_weights.pth\") == False:\n    # number of training epochs\nepochs = 3\ncurrent = 1\n# for each epoch\nwhile current <= epochs:\n\n    print(f'\\nEpoch {current} / {epochs}:')\n\n    # train model\n    train_loss, _ = train()\n\n    # evaluate model\n    valid_loss, _ = evaluate()\n\n    # save the best model\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        #torch.save(model.state_dict(), 'saved_weights.pth')\n\n    # append training and validation loss\n    #train_losses.append(train_loss)\n    #valid_losses.append(valid_loss)\n\n    print(f'\\n\\nTraining Loss: {train_loss:.3f}')\n    print(f'Validation Loss: {valid_loss:.3f}')\n\n    current = current + 1\n#else:\n    #print(\"Got weights!\")\n    # load weights of best model\n    #model.load_state_dict(torch.load(\"saved_weights.pth\"))\n    #model.load_state_dict(torch.load(\"/content/drive/MyDrive/saved_weights.pth\"), strict=False)\n\n# get predictions for test data\n# gc.collect()\n# torch.cuda.empty_cache()\n\nwith torch.no_grad():\n    preds = model(test_seq.to(device), test_mask.to(device))\n    #preds = model(test_seq, test_mask)\n    preds = preds.detach().cpu().numpy()\n\n\nprint(\"Performance:\")\n# model's performance\npreds = np.argmax(preds, axis=1)\nprint('Classification Report')\nprint(classification_report(test_y, preds))\n\nprint(\"Accuracy: \" + str(accuracy_score(test_y, preds)))","metadata":{"execution":{"iopub.status.busy":"2024-02-07T03:55:11.393822Z","iopub.execute_input":"2024-02-07T03:55:11.394260Z","iopub.status.idle":"2024-02-07T07:34:51.024193Z","shell.execute_reply.started":"2024-02-07T03:55:11.394222Z","shell.execute_reply":"2024-02-07T07:34:51.023249Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"cpu\n41157\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"865b5d8c230e4273b44d2f846c9eb4e3"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"498716b9a29f4791b213da929df94174"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0a41acb562a44629ccc47e7c8fda8c6"}},"metadata":{}},{"name":"stdout","text":"\n\nEpoch 1 / 3:\nBatch 1029/1029 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n\nEvaluating...\nBatch 129/129 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.03, accuracy=0\n\nTraining Loss: 0.034\nValidation Loss: 0.026\n\nEpoch 2 / 3:\nBatch 1029/1029 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n\nEvaluating...\nBatch 129/129 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n\nTraining Loss: 0.023\nValidation Loss: 0.023\n\nEpoch 3 / 3:\nBatch 1029/1029 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n\nEvaluating...\nBatch 129/129 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.02, accuracy=0\n\nTraining Loss: 0.018\nValidation Loss: 0.024\nPerformance:\nClassification Report\n              precision    recall  f1-score   support\n\n           0       0.73      0.77      0.75       548\n           1       0.68      0.71      0.69       991\n           2       0.87      0.77      0.82       771\n           3       0.72      0.73      0.72      1143\n           4       0.78      0.78      0.78       663\n\n    accuracy                           0.74      4116\n   macro avg       0.75      0.75      0.75      4116\nweighted avg       0.75      0.74      0.75      4116\n\nAccuracy: 0.7446550048590865\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We use a dropout layer for some regularization and a fully-connected layer for our output. We are returning the raw output of the last layer since that is required for the cross-entropy loss function in PyTorch to work. Create an instance and move it to the GPU","metadata":{"id":"MXyrki17EzVl"}},{"cell_type":"code","source":"# Instantiate the model and move to classifier\nmodel = SentimentClassifier(len(class_names))\nmodel = model.to(device)","metadata":{"id":"5eh4ytjBEzVm","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model Characterstics","metadata":{"id":"wqNrk3laEzVr"}},{"cell_type":"code","source":"# Number of hidden units\nprint(bert_model.config.hidden_size)","metadata":{"id":"iFkXhnrLEzVr","outputId":"f065e9d5-9ca5-4a7e-9c20-e953d5da05f1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training Phase\n\nwe’ll use the AdamW optimizer provided by Hugging Face. It corrects weight decay. We’ll also use a linear scheduler with no warmup","metadata":{"id":"_TcSxv4NEzVv"}},{"cell_type":"code","source":"# Number of iterations \nEPOCHS = 10\n\n# Optimizer Adam \noptimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n\ntotal_steps = len(train_data_loader) * EPOCHS\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=total_steps\n)\n\n# Set the loss function \nloss_fn = nn.CrossEntropyLoss().to(device)","metadata":{"id":"CEQfhsdnEzVw","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for a single training iteration\ndef train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n    model = model.train()\n    losses = []\n    correct_predictions = 0\n    \n    for d in data_loader:\n        input_ids = d[\"input_ids\"].to(device)\n        attention_mask = d[\"attention_mask\"].to(device)\n        targets = d[\"targets\"].to(device)\n        \n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        \n        _, preds = torch.max(outputs, dim=1)\n        loss = loss_fn(outputs, targets)\n        correct_predictions += torch.sum(preds == targets)\n        losses.append(loss.item())\n        \n        # Backward prop\n        loss.backward()\n        \n        # Gradient Descent\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n    \n    return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{"id":"jYmCvwhmEzVz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Write a function to evaluate model performance","metadata":{"id":"qSUZ7gXeEzV2"}},{"cell_type":"code","source":"def eval_model(model, data_loader, loss_fn, device, n_examples):\n    model = model.eval()\n    \n    losses = []\n    correct_predictions = 0\n    \n    with torch.no_grad():\n        for d in data_loader:\n            input_ids = d[\"input_ids\"].to(device)\n            attention_mask = d[\"attention_mask\"].to(device)\n            targets = d[\"targets\"].to(device)\n            \n            # Get model ouptuts\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n            )\n            \n            _, preds = torch.max(outputs, dim=1)\n            loss = loss_fn(outputs, targets)\n            \n            correct_predictions += torch.sum(preds == targets)\n            losses.append(loss.item())\n            \n    return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{"id":"Yil2jCZfEzV2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Write the training Loop and store the best training state.","metadata":{"id":"vZRB5jbrEzV5"}},{"cell_type":"code","source":"%%time\n\nhistory = defaultdict(list)\nbest_accuracy = 0\n\nfor epoch in range(EPOCHS):\n    \n    # Show details \n    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n    print(\"-\" * 10)\n    \n    train_acc, train_loss = train_epoch(\n        model,\n        train_data_loader,\n        loss_fn,\n        optimizer,\n        device,\n        scheduler,\n        len(df_train)\n    )\n    \n    print(f\"Train loss {train_loss} accuracy {train_acc}\")\n    \n    # Get model performance (accuracy and loss)\n    val_acc, val_loss = eval_model(\n        model,\n        val_data_loader,\n        loss_fn,\n        device,\n        len(df_val)\n    )\n    \n    print(f\"Val   loss {val_loss} accuracy {val_acc}\")\n    print()\n    \n    history['train_acc'].append(train_acc)\n    history['train_loss'].append(train_loss)\n    history['val_acc'].append(val_acc)\n    history['val_loss'].append(val_loss)\n    \n    # If we beat prev performance\n    if val_acc > best_accuracy:\n        torch.save(model.state_dict(), 'best_model_state.bin')\n        best_accuracy = val_acc","metadata":{"id":"tz0rylI3EzV5","outputId":"545b8419-84b1-4b11-af85-1c45bdc118d9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above took a lot of time but it's finally working. Now, we can plot the training and validation accuracy.","metadata":{"id":"h197cMl1Hve2"}},{"cell_type":"code","source":"# Plot training and validation accuracy\nplt.plot(history['train_acc'], label='train accuracy')\nplt.plot(history['val_acc'], label='validation accuracy')\n\n# Graph chars\nplt.title('Training history')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.ylim([0, 1]);","metadata":{"id":"mkOsxRIcHgKt","outputId":"11116244-c94e-43de-f9c5-58dff0c7cc75","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model = SentimentClassifier(len(class_names))\nloaded_model = loaded_model.to(device)\nloaded_model.load_state_dict(torch.load('best_model_state.bin'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_acc, _ = eval_model(\n  loaded_model,\n  test_data_loader,\n  loss_fn,\n  device,\n  len(df_test)\n)\n\ntest_acc.item()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Evaluation","metadata":{"id":"XJ-hTsMQITml"}},{"cell_type":"code","source":"test_acc, _ = eval_model(\n  model,\n  test_data_loader,\n  loss_fn,\n  device,\n  len(df_test)\n)\n\ntest_acc.item()","metadata":{"id":"q53eNoW2IS7C","outputId":"62b82769-6859-49b8-89c3-3fad47b76763","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define a helper function to get predictions from our models. This is similar to the evaluation function, except that we’re storing the text of the reviews and the predicted probabilities","metadata":{"id":"3kjQ5tI8IbIl"}},{"cell_type":"code","source":"def get_predictions(model, data_loader):\n    model = model.eval()\n\n    review_texts = []\n    predictions = []\n    prediction_probs = []\n    real_values = []\n\n    with torch.no_grad():\n        for d in data_loader:\n            texts = d[\"review_text\"]\n            input_ids = d[\"input_ids\"].to(device)\n            attention_mask = d[\"attention_mask\"].to(device)\n            targets = d[\"targets\"].to(device)\n\n            # Get outouts\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n            )\n            _, preds = torch.max(outputs, dim=1)\n\n            review_texts.extend(texts)\n            predictions.extend(preds)\n            prediction_probs.extend(outputs)\n            real_values.extend(targets)\n\n    predictions = torch.stack(predictions).cpu()\n    prediction_probs = torch.stack(prediction_probs).cpu()\n    real_values = torch.stack(real_values).cpu()\n\n    return review_texts, predictions, prediction_probs, real_values","metadata":{"id":"C2gJhrUHIfsm","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n    model,\n    test_data_loader\n)","metadata":{"id":"18mV-rdaIy-T","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred, target_names=class_names))","metadata":{"id":"1uvXvTrQVcK6","outputId":"2f139229-c8e1-4b2d-ffd8-63af9520fc0a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_confusion_matrix(confusion_matrix):\n    hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n    hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n    hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n    plt.ylabel('True sentiment')\n    plt.xlabel('Predicted sentiment');\n\ncm = confusion_matrix(y_test, y_pred)\ndf_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\nshow_confusion_matrix(df_cm)","metadata":{"id":"YWVfnVW3VgL-","outputId":"ffc9aecb-4868-4e3c-d3b4-e374372ec3f1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This confirms that our model is having difficulty classifying neutral reviews. It mistakes those for negative and positive at a roughly equal frequency.\n\nThat’s a good overview of the performance of our model.","metadata":{"id":"jp2juwgkIyiB"}},{"cell_type":"markdown","source":"## Predicting on raw text","metadata":{"id":"z6AQl1YoEzV8"}},{"cell_type":"code","source":"review_text = \"I love completing my todos! Best app ever!!!\"","metadata":{"id":"S4CWFF0MEzV9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_review = tokenizer.encode_plus(\n    review_text,\n    max_length=MAX_LEN,\n    add_special_tokens=True,\n    return_token_type_ids=False,\n    pad_to_max_length=True,\n    return_attention_mask=True,\n    return_tensors='pt',\n)","metadata":{"id":"TOelFhlsSiK2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids = encoded_review['input_ids'].to(device)\nattention_mask = encoded_review['attention_mask'].to(device)\n\noutput = model(input_ids, attention_mask)\n_, prediction = torch.max(output, dim=1)\n\nprint(f'Review text: {review_text}')\nprint(f'Sentiment  : {class_names[prediction]}')","metadata":{"id":"3LZm3Ag0WGpi","outputId":"adc38462-7a4a-4554-c856-f8af32c3c8c2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}